## 并发问题

这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个**核心矛盾一直存在，就是这三者的速度差异**。CPU 和内存的速度差异可以形象地描述为：CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。内存和 I/O 设备的速度差异就更大了，内存是天上一天，I/O 设备是地上十年。

程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论，程序整体的性能取决于最慢的操作，即读写 I/O 设备，也就是说单方面提高 CPU 性能是无效的。为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：

1. CPU 增加了缓存，以均衡与内存的速度差异；
2. 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
3. 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。（程序的局部性原理）

现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。

**源头之一：缓存导致的可见性问题**

在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。

<div align="center"><img width="40%" src="http://blogfileqiniu.isjinhao.site/e8098132-6bfc-454c-90be-cba797415ff4" /></div>
多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。

<div align="center"><img width="50%" src="http://blogfileqiniu.isjinhao.site/5d0314e8-27ed-41a8-bffa-a843c7603fb1" /></div>
虽然Java程序是运行在Java虚拟机上的，但是由于速度不匹配的问题不能被解决，所以虚拟机也无法屏蔽这个问题，同时虚拟机提出了Java Memory Model来与实际的硬件环境相对应。

<div align="center"><img width="50%" src="http://blogfileqiniu.isjinhao.site/5de12b30-0e0d-4648-9432-b026402fe9bd" /></div>
所以我们经常会说类似于下面的代码运行出来的结果是错误的。而这个错误是由可见性引起的。

```java
public class Test {
    private long count = 0;
    private void add10K() {
        int idx = 0;
        while(idx++ < 10000) {
            count += 1;
        }
    }
    public static long calc() {
        final Test test = new Test();
        Thread th1 = new Thread(()->{
            test.add10K();
        });
        Thread th2 = new Thread(()->{
            test.add10K();
        });
        th1.start();
        th2.start();
        th1.join();
        th2.join();
        return count;
    }
}
```

**源头之二：线程切换带来的原子性问题**

由于 IO 太慢，早期操作系统就发明了多进程，即便在单核的 CPU 上我们也可以一边听着歌，一边写 Bug，这个就是多进程的功劳。它的具体做法是某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个 50 毫秒称为“**时间片**”。

在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。

这里的进程在等待 IO 时之所以会释放 CPU 使用权，是为了让 CPU 在这段等待时间里可以做别的事情，这样一来 CPU 的使用率就上来了；此外，如果这时有另外一个进程也读文件，读文件的操作就会排队，磁盘驱动在完成一个进程的读操作后，发现有排队的任务，就会立即启动下一个读操作，这样 IO 的使用率也上来了。

早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。而线程和进程的区别是：线程是可执行的单位，进程是用有资源的单位。

<div align="center"><img width="60%" src="http://blogfileqiniu.isjinhao.site/d5a0ca0a-6515-4775-ad4d-83833a1b2b82" /></div>
Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的`count += 1`，至少需要三条 CPU 指令。

- 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
- 指令 2：之后，在寄存器中执行 +1 操作；
- 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

操作系统做任务切换，可以发生在任何一条**CPU 指令**执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。

<div align="center"><img width="60%" src="http://blogfileqiniu.isjinhao.site/894f0ec5-7b4a-4c9b-a22b-38471b015a6d" /></div>
我们潜意识里面觉得 count+=1 这个操作是一个不可分割的整体，就像一个原子一样，线程的切换可以发生在 count+=1 之前，也可以发生在 count+=1 之后，但就是不会发生在中间。**我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性**。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。因此，很多时候我们需要在高级语言层面保证操作的原子性。如Java的 synchronized 。

**源头之三：优化带来的有序性问题**

那并发编程里还有没有其他有违直觉容易导致诡异 Bug 的技术呢？有的，就是有序性。顾名思义，有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中：“a=6；b=7；”，编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的 Bug。

在 Java 领域一个经典的案例就是利用双重检查创建单例对象，例如下面的代码：在获取实例 getInstance() 的方法中，我们首先判断 instance 是否为空，如果为空，则锁定 Singleton.class 并再次检查 instance 是否为空，如果还为空则创建 Singleton 的一个实例。

```java
public class Singleton {
    static Singleton instance;
    static Singleton getInstance(){
        if (instance == null) {
            synchronized(Singleton.class) {
                if (instance == null)
                    instance = new Singleton();
            }
        }
        return instance;
    }
}
```

写这段代码的思维是这样的：假设有两个线程 A、B 同时调用 getInstance() 方法，他们会同时发现 `instance == null` ，于是同时对 Singleton.class 加锁，此时 JVM 保证只有一个线程能够加锁成功（假设是线程 A），另外一个线程则会处于等待状态（假设是线程 B）；线程 A 会创建一个 Singleton 实例，之后释放锁，锁释放后，线程 B 被唤醒，线程 B 再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程 B 检查 `instance == null` 时会发现，已经创建过 Singleton 实例了，所以线程 B 不会再创建一个 Singleton 实例。

这看上去一切都很完美，无懈可击，但实际上这个 getInstance() 方法并不完美。问题出在哪里呢？出在 new 操作上，我们以为的 new 操作应该是：

1. 分配一块内存 M；
2. 在内存 M 上初始化 Singleton 对象；
3. 然后 M 的地址赋值给 instance 变量。

但是实际上优化后的执行路径却是这样的：

1. 分配一块内存 M；
2. 将 M 的地址赋值给 instance 变量；
3. 最后在内存 M 上初始化 Singleton 对象。

优化后会导致什么问题呢？我们假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 `instance != null` ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。

<div align="center"><img width="60%" src="http://blogfileqiniu.isjinhao.site/7ce4aba3-146e-4c0f-a071-4e42a91739d0" /></div>
这个问题很明显是指令重排序导致的，所以解决方案也自然是禁止指令重排序。



## 并发的一些概念

在学习并发的过程中我们经常会遇到一些概念，比如并发和并行、多处理器和多核处理器、超线程、上下文切换、中断、阿姆达尔定律等等。这其中除了并发和并行这种简单概念，其他的大多数都会涉及到操作系统和硬件层次。所以并发是一项从应用层贯穿到硬件层次的技术，真正学懂并发不仅仅是理解`synchronized`、`volatile`等应用层次的知识点，而是要真正理解诸如操作系统对线程是如何管理的，程序在计算机中是怎么执行的这种底层理论知识点。所以我们下面会就这些问题进行讨论。

**并发和并行**

如果某个系统支持两个或者多个动作（Action）**同时存在**，那么这个系统就是一个**并发系统**。如果某个系统支持两个或者多个动作**同时执行**，那么这个系统就是一个**并行系统**。并发系统与并行系统这两个定义之间的关键差异在于**“存在”**这个词。

在并发程序中可以同时拥有两个或者多个线程。这意味着，如果程序在单核处理器上运行，那么这两个线程将交替地换入或者换出内存。这些线程是同时“存在”的，即每个线程都处于执行过程中的某个状态。如果程序能够并行执行，那么就一定是运行在多核处理器上。此时，程序中的每个线程都将分配到一个独立的处理器核上，因此可以同时运行。

我相信你已经能够得出结论——**“并行”概念是“并发”概念的一个子集**。也就是说，你可以编写一个拥有多个线程或者进程的并发程序，但如果没有多核处理器来执行这个程序，那么就不能以并行方式来运行代码。因此，凡是在求解单个问题时涉及多个执行流程的编程模式或者执行行为，都属于并发编程的范畴。

**多核处理器和多处理器**

我们现在使用的处理器一般都是多核处理器，其中的**核**是执行指令的单位，即算数逻辑单元（ALU）。单核单处理器只能完成并发操作，而多核处理器可以完成并行操作。多处理器和多核处理器想解决的问题是一致的，就是让计算机能真正执行并行操作，但是由于多核处理器的综合水平优于多处理器，所以现在基本就都是多核处理器（专用计算机不考虑）。至于为什么多核处理器优于多处理器，笔者的看法就是我们刚才说过的可见性问题，如果在一个核中，可以多铺设内部总线来加速每个ALU缓存的缓存更新。而对于是多处理器，如果CPU间总线少了，就会产生大量的总线冲突进而降低效率，如果总线多了，CPU和CPU之间都连在一起了，那还不如做成一个CPU呢。下面便是一个多核处理器的架构图。

<div align="center"><img width="80%" src="http://blogfileqiniu.isjinhao.site/e2556626-5a77-4476-93ee-150fea6a0f08" /></div>
我们上面的图示是同构多核处理器，于此对应的还有异构多核处理器。顾名思义，异构和同构的区别就是核的设计不同。异构的处理器中可能有CPU核、GPU核、DSP核和NPU核等等。

<div align="center"><img width="80%" src="http://blogfileqiniu.isjinhao.site/1b8af0cd-91ec-4953-855d-424d53427c8f" /></div>
**超线程**

在超线程技术诞生之前，一个物理核对应一个线程，即N核CPU最多支持N个线程并行。但是超线程技术可以把一个物理核虚拟成两个逻辑核，这样N个CPU就可以支持2N和线程并行。虽然性能没法真正达到两倍于非超线程模式，但是性能提升也是巨大的（之前看过一篇文章好像说是整体性能提升50%，但是现在找不到了）。

<div align="center"><img width="35%" src="http://blogfileqiniu.isjinhao.site/56f5cfa1-79d5-4d3c-baf2-2508b43e88d4" /></div>
超线程技术的执行过程类似于我们上面的这张图。图中RAM里有四个线程的指令，它们进入前端后会被解码和重排序（引起并发重排序问题的原因之一）。前端优化以后进入执行部件，由于执行部件的速度非常快，它可以同时运行两个线程的指令。而为什么超线程达不到两倍性能提升呢？我们从图中可以看到有一些白色的不属于四个进程的指令，他们其实是管道气泡。就是说在前端优化后某些指令不能同时运行，比如需要同时使用同一段总线的。这时候就需要插入一些空的指令来将指令错开，以至于两个逻辑内核不能有两个物理内核的性能。理解了管道气泡之后我们也可以理解为什么一个物理内核只虚拟成两个逻辑内核，因为虚拟的越多，冲突就会越多，性能不仅难以提升可能还会下降。

我们现在编程时使用的都是用逻辑内核。比如Java获得核数的API就是逻辑内核。

```java
public static void main(String[] args) {
    int availProcessors = Runtime.getRuntime().availableProcessors();
    System.out.println("avail processors count: " + availProcessors);
}
```

**上下文切换**

在我们超线程的图里可以看到，程序在运行之前会进行前端优化，同时在程序运行之后又会将常见的指令或数据存在告诉缓存中以便于之后寻找。当一个核在执行某个线程的指令的时候，我们将其切换到另一个线程执行，会引起前端优化的信息被丢弃，高速缓存的信息会不起作用、PC计数器等的数据需要被保存以及后期的恢复。这个过程便是上下文切换。上下文切换很明显会对整个程序的执行效率造成重大影响。

**阿姆达尔定律**

程序在多核处理器上执行的时候是可以达到并行的效果的。但是如果我们软件写的太烂，比如全部都在一个线程里完成，那么肯定会无法利用CPU的全部性能进而导致程序卡顿。那么串行并行与性能之间的关系是什么呢？这个就是阿姆达尔定律：

​		$S=\frac{1}{((1-p)+p/n}$。（S是和单核CPU对比的加速比）

公式里的 n 可以理解为 CPU 的核数，p 可以理解为并行百分比，那（1-p）就是串行百分比了，也就是我们假设的 5%。我们再假设 CPU 的核数（也就是 n）无穷大，那加速比 S 的极限就是 20。也就是说，如果我们的串行率是 5%，那么我们无论采用什么技术，最高也就只能提高 20 倍的性能。

**中断**

一般来说我们遇见的中断概念类似如下：

> 在程序运行时，系统外部、内部或现行程序本身若出现紧急事件，处理器必须立即强行中止现行程序的运行，改变机器的工作状态并启动相应的程序来处理这些事件，然后再恢复原来的程序运行，这一过程称为中断（interrupt）。

这个定义看起来很简单，但是我们需要关注以下三个方面的知识：

- 强行中止：在程序执行的过程中，一条指令的执行应该是一个原子操作，强行中止并不是指一条指令执行一半不执行了。而是说这条指令执行完了，本应该执行的下一条指令被中断处理程序的指令所替代。
- 怎么检测紧急事件：如果我们现在有100个线程，如果用软件的思维是考虑，我们需要轮询这100个线程，轮询是一个串行化的操作。但是硬件不同，硬件的引脚信号都是并行的。所以当有中断请求进来的时候，通过优先级逻辑电路就可以让我们优先响应中断信号。比如图中的8086有NMI非屏蔽中断和INTR可屏蔽中断引脚。

<div align="center"><img width="40%" src="http://blogfileqiniu.isjinhao.site/c58eb473-9057-4e0b-be19-ff7e54696201" /></div>
- 改变工作状态：中断处理程序和普通的程序不是同一个执行线路，所以中断的使用会导致上下文切换。

**系统调用**

我们知道，操作系统是硬件上的第一层软件，所以它会操控一些很核心的外围设备，比如计数器、中断处理器、并行串行接口等等。这个设备因为很重要很重要，所以不可能让用户程序去操作，同时操作系统提供了很多和接口来供其他应用调用。接口的背后实际上也是程序，当系统运行这些程序的时候便是处于内核态，当系统运行用户程序的时候便是处于用户态。调用接口的过程被称为系统调用。

在Linux系统上，用户程序想要调用系统调用，只能通过中断的方式进行，这就又引发上下文切换的问题了。所以系统在内核态和用户态转换的时候会降低程序的运行效率。

**POSIX**

本篇文章的最后，我们再看一个名词POISX。我们知道Unix系统是当今主流操作系统的祖宗，Linux也是仿造Unix出现的产品。但是由于加上早期的Unix不够完善，很多开发者基于原始的Unix系统开发了很多与Unix基本兼容但又不完全兼容的OS，通称Unix-like OS。局面非常混乱，为了提高兼容性和应用程序的可移植性，标准化Unix-like OS，IEEE提出了大家都应该遵守的POSIX标准，全称 Portable Operating System Interface，可移植操作系统接口。这个标准里定义了应用程序编程接口（API）、Shell接口和实用程序接口，以实现与Unix和其他操作系统的变体的软件兼容性。后来，Unix这个名字成为了商标，只有花钱进行POSIX标准兼容性测试并通过了的OS，才能称为Unix，其余的OS，最多称为Unix-like OS或者*nix OS。



